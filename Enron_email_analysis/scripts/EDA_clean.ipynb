{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tDloRlyHjuM"
   },
   "source": [
    "## Importing Libraries and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10182,
     "status": "ok",
     "timestamp": 1750104408096,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "88z-mDSQpVSy",
    "outputId": "4d8dfa46-bd46-4c5c-896f-14c563222bce"
   },
   "outputs": [],
   "source": [
    "!pip install lexicalrichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7932,
     "status": "ok",
     "timestamp": 1750104416034,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "pJvHBahlqokY",
    "outputId": "f5a26db6-6d58-4b03-b4b1-03a2eb75e3ff"
   },
   "outputs": [],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750107053539,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "iHYOit8MIWYt"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.cluster import DBSCAN\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import csv, sys\n",
    "from google.colab import drive\n",
    "import os\n",
    "from lexicalrichness import LexicalRichness\n",
    "from rapidfuzz import process, fuzz\n",
    "import time\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1750104428219,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "TPUfEMzjIv4M",
    "outputId": "b2e92f96-b631-4361-a3ed-4733875ebcb0"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1750104429091,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "xAMOL-MEI8ny"
   },
   "outputs": [],
   "source": [
    "nlp_lemma = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1750104429689,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "wp57bbkkJz1l"
   },
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO50mn2iIOsP"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750104429703,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "bdUMktmKMmef",
    "outputId": "3f3d5bda-bcd8-4eba-d766-b63e6bd57a82"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97022,
     "status": "ok",
     "timestamp": 1750104526727,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "DsjdQrrEFr0G",
    "outputId": "8d9bf8a3-c0a8-4d83-8612-54e02ae1a8e7"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "executionInfo": {
     "elapsed": 28135,
     "status": "ok",
     "timestamp": 1750104554864,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "ZEQt21Y1GgLO",
    "outputId": "0758e5d4-0228-42d0-f6f8-6571d2bdc291"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/content/drive/MyDrive/NLP_Project/df_clean.csv',\n",
    "    sep='§')\n",
    "\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7P1_4ogHnfX"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oERK4ome-X0"
   },
   "source": [
    "### Feature Engineering and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6764,
     "status": "ok",
     "timestamp": 1750104561809,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "CwdvTqece69n"
   },
   "outputs": [],
   "source": [
    "df['char_length'] = df['Cleaned_Body_n'].astype(str).str.len()\n",
    "df['word_length'] = df['Cleaned_Body_n'].astype(str).str.split().str.len()\n",
    "df['avg_word_length'] = df.apply(\n",
    "    lambda row: row['char_length'] / row['word_length'] if row['word_length'] > 0 else 0,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11402,
     "status": "ok",
     "timestamp": 1750104573224,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "5U7j-nuwgcCA"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize words\n",
    "def tokenize(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())  # ignore punctuation\n",
    "    return [t for t in tokens if t not in stop_words and len(t) > 1]\n",
    "\n",
    "# Tokenization and count\n",
    "df['tokens'] = df['Cleaned_Body_n'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750104573235,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "JiKTTZv1uKN-"
   },
   "outputs": [],
   "source": [
    "level_order = [\"High\", \"Medium\", \"Low\"]\n",
    "level_colors = {\n",
    "    'High': '#1f77b4',\n",
    "    'Medium': '#ff7f0e',\n",
    "    'Low': '#2ca02c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750104573561,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "f8dEgwah5zfn"
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750104573575,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "W9XeGN6n5hj9",
    "outputId": "254137ee-94d5-4148-c848-0889ec45baa4"
   },
   "outputs": [],
   "source": [
    "df['year_month'] = df['Date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TRiT5HnIhcq"
   },
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1750104665772,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "jneweI7KVpHY",
    "outputId": "61b7d797-89ec-4447-cf20-10c85aabee6b"
   },
   "outputs": [],
   "source": [
    "people_per_level = df[['From', 'Level']].drop_duplicates().groupby('Level').size().reset_index()\n",
    "people_per_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1750104665778,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "w0UOwhTOfIYL",
    "outputId": "4566b141-1e32-40c8-8423-e38a72d93699"
   },
   "outputs": [],
   "source": [
    "df.groupby('Level')['char_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1750104665843,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "Ps-kI8-CK6DJ",
    "outputId": "28673f59-3ab3-482e-c678-c5c4fc4b2ea5"
   },
   "outputs": [],
   "source": [
    "df.groupby('Level')['word_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "executionInfo": {
     "elapsed": 1161,
     "status": "ok",
     "timestamp": 1750104667005,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "kwHsbN2qXFTN",
    "outputId": "f3d76a8f-6950-474e-9b33-72ecb068b5fb"
   },
   "outputs": [],
   "source": [
    "summary_stats = pd.DataFrame({\n",
    "    'Total Emails': df.groupby('Level').size(),\n",
    "    'Unique Senders': df.groupby('Level')['From'].nunique(),\n",
    "    'Average Length (Chars)': df.groupby('Level')['char_length'].mean(),\n",
    "    'Average Length (Words)': df.groupby('Level')['word_length'].mean(),\n",
    "    'Average Word Length': df.groupby('Level')['avg_word_length'].mean(),\n",
    "    'Avg Tokens per Email': df['tokens'].apply(len).groupby(df['Level']).mean(),}).round(2)\n",
    "\n",
    "summary_stats = summary_stats.reindex(['High', 'Medium', 'Low'])\n",
    "\n",
    "# Plots\n",
    "fig, axes = plt.subplots(1, summary_stats.shape[1], figsize=(20, 4))\n",
    "\n",
    "for i, column in enumerate(summary_stats.columns):\n",
    "    axes[i].bar(summary_stats.index, summary_stats[column],\n",
    "        color=[level_colors[level] for level in summary_stats.index])\n",
    "    axes[i].set_title(column, fontsize=10)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('Email Summary Statistics by Hierarchical Level', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O-qpdoG_4pe"
   },
   "source": [
    "### Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHnwGBv6btkF"
   },
   "source": [
    "###### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750104668704,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "JRIXDYT9YusA"
   },
   "outputs": [],
   "source": [
    "def lemmatize_docs(docs, batch_size=512, n_process=4):\n",
    "    all_lemmas = []\n",
    "    for doc in nlp_lemma.pipe(docs, batch_size=batch_size, n_process=n_process):\n",
    "        lemmas = [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if token.is_alpha and not token.is_stop and len(token) > 1\n",
    "        ]\n",
    "        all_lemmas.append(lemmas)\n",
    "    return all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 973482,
     "status": "ok",
     "timestamp": 1750105642212,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "bgz7tu5NYyBz",
    "outputId": "d07ebab7-58b2-483b-e9a2-dcefc751290b"
   },
   "outputs": [],
   "source": [
    "texts = df[\"Cleaned_Body_n\"].dropna().astype(str)\n",
    "chunk_size = 8000\n",
    "lemmas_combined = []\n",
    "\n",
    "for start in range(0, len(texts), chunk_size):\n",
    "    end = min(start + chunk_size, len(texts))\n",
    "    chunk = texts.iloc[start:end].tolist()\n",
    "\n",
    "    lemmas_chunk = lemmatize_docs(chunk, batch_size=512, n_process=4)\n",
    "    lemmas_combined.extend(lemmas_chunk)\n",
    "\n",
    "    print(f\"Chunk completed: {start} → {end}\")\n",
    "\n",
    "# Assign lemmas to columns\n",
    "df.loc[texts.index, \"tokens_lemmatized\"] = pd.Series(lemmas_combined, index=texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7248,
     "status": "ok",
     "timestamp": 1750105649464,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "WxR9iV_zXwNW",
    "outputId": "62632ab7-7bda-48b0-8bd4-4a0a182dbd4a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "levels = df['Level'].dropna().unique()\n",
    "\n",
    "for lvl in levels:\n",
    "    # flatten tokens & lemmas for this level\n",
    "    tokens = [t for sub in df.loc[df['Level'] == lvl, 'tokens'].dropna() for t in sub]\n",
    "    lemmas = [l for sub in df.loc[df['Level'] == lvl, 'tokens_lemmatized'].dropna() for l in sub]\n",
    "\n",
    "    top_tokens = Counter(tokens).most_common(20)\n",
    "    top_lemmas = Counter(lemmas).most_common(20)\n",
    "\n",
    "    words, wf = zip(*top_tokens)\n",
    "    lem, lf = zip(*top_lemmas)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharex=False)\n",
    "    # Left: tokens\n",
    "    axes[0].barh(words, wf)\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_title(f'{lvl} Level: Top 20 Tokens')\n",
    "    axes[0].set_xlabel('Frequency')\n",
    "\n",
    "    # Right: lemmas\n",
    "    axes[1].barh(lem, lf)\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_title(f'{lvl} Level: Top 20 Lemmas')\n",
    "    axes[1].set_xlabel('Frequency')\n",
    "\n",
    "    fig.suptitle(f'Tokens vs Lemmas at {lvl} Level', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3467,
     "status": "ok",
     "timestamp": 1750105652938,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "ezrUNcPnUffN",
    "outputId": "e97bc535-e742-45b2-b060-5363fe461bca"
   },
   "outputs": [],
   "source": [
    "#single graph for all levels\n",
    "valid_lemmas = df['tokens_lemmatized'].dropna()\n",
    "all_lemmas   = [lemma for sublist in valid_lemmas for lemma in sublist]\n",
    "lemma_freq   = Counter(all_lemmas)\n",
    "wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(lemma_freq)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of most frequent lemmas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyUchnxCcDfu"
   },
   "source": [
    "###### Semantic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 12255,
     "status": "ok",
     "timestamp": 1750105665198,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "-KV1p2_-M8js",
    "outputId": "6bbe0af4-ef1e-4d5a-d80b-0ae9013f4b2f"
   },
   "outputs": [],
   "source": [
    "def keyword_group_rate(df, keyword_list, group_name):\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, keyword_list)) + r')\\b'\n",
    "    col_name = f'has_{group_name}'\n",
    "    df[col_name] = df['Cleaned_Body_n'].str.contains(pattern, case=False, na=False)\n",
    "    return df.groupby('Level')[col_name].mean().rename(group_name)\n",
    "\n",
    "# Groups\n",
    "Courtesy = ['please', 'thanks', 'thank', 'regards', 'sincerely', 'appreciate', 'best']\n",
    "Orders = ['confirm', 'forward', 'schedule', 'prepare', 'submit', 'review', 'organize','must','fix', 'should']\n",
    "Crisis = ['crisis', 'issue', 'problem', 'concern', 'urgent', 'delay', 'fail', 'risk', 'pressure']\n",
    "\n",
    "# Frequency within each category\n",
    "results_grouped = pd.concat([\n",
    "    keyword_group_rate(df, Courtesy, 'courtesy'),\n",
    "    keyword_group_rate(df, Orders, 'orders'),\n",
    "    keyword_group_rate(df, Crisis, 'crisis')], axis=1)\n",
    "\n",
    "display(results_grouped.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1750105665471,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "NyY0unAnOMZ5",
    "outputId": "bdaeaa37-de85-4bfc-ad70-e18491a6556b"
   },
   "outputs": [],
   "source": [
    "# Bar chart with frequency within each semantic group of word\n",
    "\n",
    "results_plot = results_grouped.T\n",
    "results_plot = results_plot[level_order]\n",
    "\n",
    "results_plot.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Proportion of Emails per Word Category by Hierarchical Level')\n",
    "plt.xlabel('Word Category')\n",
    "plt.ylabel('Proportion of Emails')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Hierarchical Level')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ6Yzux_pC9J"
   },
   "source": [
    "###### Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14278,
     "status": "ok",
     "timestamp": 1750105679752,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "WEXutDoJs3Fw"
   },
   "outputs": [],
   "source": [
    "# Compute MTLD\n",
    "def compute_mtld(tokens):\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    text = ' '.join(tokens)\n",
    "    return LexicalRichness(text).mtld()\n",
    "\n",
    "df['mtld'] = df['tokens'].apply(compute_mtld)\n",
    "\n",
    "mtld_stats = (\n",
    "    df.groupby('Level')['mtld']\n",
    "      .mean()\n",
    "      .round(2)\n",
    "      .reindex(level_order)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750105679783,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "z_xXP8THtBTo",
    "outputId": "df84db10-e241-4ea1-8c34-3c212a2fc2fc"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "title = 'Average MTLD by Hierarchical Level'\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(\n",
    "    mtld_stats.index,\n",
    "    mtld_stats.values,\n",
    "    color=[level_colors[level] for level in level_order]\n",
    ")\n",
    "plt.title(title)\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('MTLD')\n",
    "plt.ylim(0, mtld_stats.max() * 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21080,
     "status": "ok",
     "timestamp": 1750105700864,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "9q0lau34tMQJ"
   },
   "outputs": [],
   "source": [
    "# Compute MATTR\n",
    "def compute_mattr(tokens, window=25):\n",
    "    if not tokens or len(tokens) < window:\n",
    "        return None\n",
    "    text = ' '.join(tokens)\n",
    "    return LexicalRichness(text).mattr(window_size=window)\n",
    "\n",
    "# Apply\n",
    "df['mattr'] = df['tokens'].apply(lambda x: compute_mattr(x))\n",
    "\n",
    "mattr_stats = (\n",
    "    df.groupby('Level')['mattr']\n",
    "      .mean()\n",
    "      .round(2)\n",
    "      .reindex(level_order)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1750105700982,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "G9cV7YeCtS-3",
    "outputId": "306a1fde-d88b-4202-f48f-08adbb4764d4"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(\n",
    "    level_order,\n",
    "    mattr_stats.values,\n",
    "    color=[level_colors[level] for level in level_order]\n",
    ")\n",
    "plt.title('Average MATTR by Hierarchical Level')\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('MATTR')\n",
    "plt.ylim(0, mattr_stats.max() * 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPukyKv9xcns"
   },
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1750105747665,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "EQCIACVc69tu"
   },
   "outputs": [],
   "source": [
    "def extract_entities(texts):\n",
    "    return [\n",
    "        [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        for doc in nlp_ner.pipe(texts, batch_size=512, n_process=8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1276955,
     "status": "ok",
     "timestamp": 1750107040209,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "9vFGbq--7XJD",
    "outputId": "04d00a3f-8d48-45bf-d261-62b0ec28a919"
   },
   "outputs": [],
   "source": [
    "df[\"Cleaned_Body_n\"] = df[\"Cleaned_Body_n\"].fillna(\"\")\n",
    "texts = df[\"Cleaned_Body_n\"].astype(str).tolist()\n",
    "\n",
    "chunk_size = 10000\n",
    "all_entities = []\n",
    "\n",
    "for start in range(0, len(texts), chunk_size):\n",
    "    end = min(start + chunk_size, len(texts))\n",
    "    chunk = texts[start:end]\n",
    "\n",
    "    print(f\"Processing chunk: {start}–{end}...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    chunk_entities = extract_entities(chunk)\n",
    "\n",
    "    print(f\"Done in {time.time() - t0:.2f}s\")\n",
    "    all_entities.extend(chunk_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1750107040578,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "LhckH707xhyZ",
    "outputId": "f300fa32-b95b-4599-f34c-43832916b036"
   },
   "outputs": [],
   "source": [
    "flat_entities = list(chain.from_iterable(all_entities))\n",
    "\n",
    "entity_counts = Counter(label for _, label in flat_entities)\n",
    "\n",
    "print(entity_counts.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1750107040928,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "WmG1mh3YxlC9",
    "outputId": "6fc2b1ff-5dbf-401a-b312-243412f3ace4"
   },
   "outputs": [],
   "source": [
    "org_counts = Counter(ent for ent in flat_entities if ent[1] == \"ORG\")\n",
    "\n",
    "print(org_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woxuSdGWxrhR"
   },
   "source": [
    "Since there is more than one organization referring to Enron we have decided to normalize raw organization names extracted by the NER process, collapsing variants like “Enron Corp.” or “ENRON Direct” into a single form (“enron”). It then recounts mentions of each organization and plots the Top 10 by frequency, giving a more accurate view of organization mentions in our corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750107040951,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "ia3Q42ZMlZzs"
   },
   "outputs": [],
   "source": [
    "def normalize_org(name: str) -> str:\n",
    "    name = name.lower().strip()\n",
    "    name = name.replace(\"\\\\\", \"\").replace('\"', \"\").replace(\"'\", \"\")\n",
    "    for suf in [r\"\\binc\\b\", r\"\\bcorp\\b\", r\"\\bcompany\\b\", r\"\\bco\\b\",\n",
    "                r\"\\bltd\\b\", r\"'s\\b\", r\"\\bonline\\b\"]:\n",
    "        name = re.sub(suf, \"\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    name = re.sub(r\"^enron\\b.*\", \"enron\", name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5867,
     "status": "ok",
     "timestamp": 1750107046827,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "aRCljg9qrs8B"
   },
   "outputs": [],
   "source": [
    "raw_names = [t for t, lbl in flat_entities if lbl == \"ORG\"]\n",
    "\n",
    "# Normalize\n",
    "normalized = [normalize_org(n) for n in raw_names]\n",
    "normalized = [n for n in normalized if n.strip() != \"\"]\n",
    "\n",
    "blacklist = {\"fyi\", \"log\", \"re\", \"fw\", \"hi\", \"please\", \"thanks\", \"en\"}\n",
    "\n",
    "filtered = [n for n in normalized if n not in blacklist and len(n) > 2]\n",
    "org_counts = Counter(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1750107109977,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "c4RE1eQAxvPV",
    "outputId": "6a7fdd6e-ede9-4bb4-a6c1-ffd97abcb76e"
   },
   "outputs": [],
   "source": [
    "plot_df = (pd.DataFrame(org_counts.most_common(10), columns=[\"Organization\",\"Mentions\"]).sort_values(\"Mentions\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=plot_df, x=\"Mentions\", y=\"Organization\", color=\"steelblue\")\n",
    "plt.title(\"Top 10 Named Organizations\")\n",
    "plt.xlabel(\"Mentions\")\n",
    "plt.ylabel(\"Organization\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdjoHWKwfi2V"
   },
   "source": [
    "### Email verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1750107078092,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "4krJzmApfkg2"
   },
   "outputs": [],
   "source": [
    "q_low, q_high = df['word_length'].quantile([0.25, 0.75])\n",
    "\n",
    "def verbosity_label(n):\n",
    "    if n <= q_low:\n",
    "        return \"Concise\"\n",
    "    elif n >= q_high:\n",
    "        return \"Verbose\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "df['verbosity'] = df['word_length'].apply(verbosity_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750107078103,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "EFOoPqyBZUIE",
    "outputId": "2f60c1fb-1706-4099-c69d-4c1811ab28d0"
   },
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1750107078354,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "IpkpGKoiBaFa",
    "outputId": "9042c683-7eac-47e4-d4ce-f9ad808a749d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts_lvl = (\n",
    "    df\n",
    "    .groupby(['Level', 'verbosity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "verbosity_order = ['Verbose', 'Concise', 'Normal']\n",
    "\n",
    "counts_lvl = counts_lvl.reindex(\n",
    "    index=level_order,\n",
    "    columns=verbosity_order,\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "props_lvl = counts_lvl.div(counts_lvl.sum(axis=1), axis=0)\n",
    "\n",
    "props_transposed = props_lvl.T.reindex(\n",
    "    index=verbosity_order,\n",
    "    columns=level_order\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "props_transposed.plot(\n",
    "    kind='bar',\n",
    "    ax=ax,\n",
    "    width=0.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Verbosity Category\")\n",
    "ax.set_ylabel(\"Proportion of Emails\")\n",
    "ax.set_title(\"Proportion of Emails per Level\\nacross Verbosity Categories\")\n",
    "ax.legend(title=\"Hierarchical Level\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrQeWN9zLCoz"
   },
   "source": [
    "### Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1750107079473,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "ChQWe1oy4-bP",
    "outputId": "6ac2dfe9-6c99-4483-a69e-166b0ee6b0e3"
   },
   "outputs": [],
   "source": [
    "active_users = (df.groupby(['year_month', 'Level'])['From'].nunique().unstack())\n",
    "\n",
    "emails_by_month_and_level = df.groupby(['year_month', 'Level']).size().unstack()\n",
    "\n",
    "normalized_per_active_user = emails_by_month_and_level.divide(active_users)\n",
    "\n",
    "normalized_per_active_user = normalized_per_active_user.reindex(columns=level_order)\n",
    "\n",
    "colors = [level_colors[level] for level in level_order]\n",
    "\n",
    "# Plot\n",
    "ax = normalized_per_active_user.plot(\n",
    "    kind='line',\n",
    "    figsize=(12, 5),\n",
    "    marker='o',\n",
    "    color=colors\n",
    ")\n",
    "plt.title(\"Number of emails over time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of emails\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1750107079805,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "hjZHa4kz6Pq_",
    "outputId": "91ca4eef-3dd0-4309-982f-749cd6da8d41"
   },
   "outputs": [],
   "source": [
    "avg_length_by_level = (df.groupby(['year_month', 'Level'])['word_length'].mean().unstack())\n",
    "\n",
    "avg_length_by_level = avg_length_by_level.reindex(columns=level_order)\n",
    "\n",
    "colors = [level_colors[level] for level in level_order]\n",
    "\n",
    "ax = avg_length_by_level.plot(\n",
    "    kind='line',\n",
    "    figsize=(12, 5),\n",
    "    marker='o',\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Average email length (in words) by level over time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average number of words\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1750107080306,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "MdQD1n_Y6gyj",
    "outputId": "a1f54cba-95bf-46f0-ceb6-7757aa9298c2"
   },
   "outputs": [],
   "source": [
    "crisis_by_level = (\n",
    "    df\n",
    "    .groupby(['year_month', 'Level'])['has_crisis']\n",
    "    .mean()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "crisis_by_level = crisis_by_level.reindex(columns=level_order)\n",
    "\n",
    "colors = [level_colors[level] for level in level_order]\n",
    "\n",
    "ax = crisis_by_level.plot(\n",
    "    kind='line',\n",
    "    figsize=(14, 6),\n",
    "    marker='o',\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Proportion of emails containing crisis-related words by level over time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Proportion of crisis emails\")\n",
    "plt.grid(True)\n",
    "plt.legend(title='Level')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1750107080698,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "Zhz3d8P_6uuP",
    "outputId": "fb742f73-8e4d-4b43-f577-a7a580974b18"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by mail and verbosity\n",
    "counts = (\n",
    "    df\n",
    "    .groupby(['year_month','verbosity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Plot\n",
    "ax = counts.plot(\n",
    "    figsize=(14, 6),\n",
    "    marker='o'\n",
    ")\n",
    "ax.set_title(\"Number of emails by verbosity level over time\")\n",
    "ax.set_xlabel(\"Mese\")\n",
    "ax.set_ylabel(\"Numero di email\")\n",
    "ax.grid(True)\n",
    "ax.legend(title='Verbosity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xswctz9_T37J"
   },
   "source": [
    "### Pre Topic Modelling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9709,
     "status": "ok",
     "timestamp": 1750107090409,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "mNW3o4dxbnI2",
    "outputId": "f448bb0f-7c77-4b2a-e3a6-c4e26a4b6f3a"
   },
   "outputs": [],
   "source": [
    "raw_docs = df['Cleaned_Body_n'].dropna().astype(str).tolist()\n",
    "\n",
    "valid_lemmas = df[\"tokens_lemmatized\"].dropna()\n",
    "documents_str = [\" \".join(tokens) for tokens in valid_lemmas]\n",
    "\n",
    "# Vectorize strings\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    min_df=5,\n",
    "    max_df=0.6,\n",
    "    max_features=10000  # limit to most frequent 10k terms\n",
    ")\n",
    "\n",
    "dtm = vectorizer.fit_transform(documents_str)\n",
    "\n",
    "# Extract vocab & frequencies\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Vocabulary size after lemmatization: {len(vocab)}\")\n",
    "\n",
    "word_counts = np.asarray(dtm.sum(axis=0)).flatten()\n",
    "freq_df = pd.DataFrame({'term': vocab, 'count': word_counts}).sort_values('count', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most frequent lemmatized words:\")\n",
    "print(freq_df.head(10))\n",
    "\n",
    "print(\"\\nTop 10 least frequent lemmatized words (but ≥ min_df):\")\n",
    "print(freq_df.tail(10))\n",
    "\n",
    "total_elements   = dtm.shape[0] * dtm.shape[1]\n",
    "nonzero_elements = dtm.nnz\n",
    "sparsity         = 1.0 - (nonzero_elements / total_elements)\n",
    "print(f\"\\nSparsity of the lemmatized document-term matrix: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1750107091611,
     "user": {
      "displayName": "Giada Poloni",
      "userId": "05088726081194754954"
     },
     "user_tz": -120
    },
    "id": "WNjUVZUCp0CY"
   },
   "outputs": [],
   "source": [
    "df['tokens_str'] = df['tokens'].str.join(' ')\n",
    "df['tokens_lemmatized_str'] = df['tokens_lemmatized'].str.join(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upXfw3CWIAl7"
   },
   "source": [
    "### Saving Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rz1tkric1S89"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive/NLP_Project/data.csv'\n",
    "\n",
    "df.to_csv(drive_path,sep='§')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7tDloRlyHjuM",
    "T7P1_4ogHnfX",
    "3oERK4ome-X0",
    "9TRiT5HnIhcq",
    "dHnwGBv6btkF",
    "vyUchnxCcDfu",
    "fZ6Yzux_pC9J",
    "GPukyKv9xcns",
    "sdjoHWKwfi2V",
    "qrQeWN9zLCoz",
    "Xswctz9_T37J",
    "upXfw3CWIAl7"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
